{"version":3,"sources":["../src/lib/fileID/FileIDComputer.ts","../src/lib/HashComputer.ts","../src/lib/HashIndexManager.ts","../src/lib/ExistsAsync.ts","../src/lib/ComputeHashIndexCache.ts"],"names":["Piscina","distFolder","workerUrl","FileIDComputer","workerPath","filePath","algorithms","HashComputer","targetHash","metadata","neededHashes","hashName","cid","index","hashType","createReadStream","fs","parse","parseSync","stringify","access","constants","existsAsync","path","clearInterval","INDEX_HEADERS","HashIndexManager","autosave","resolve","reject","e","csvContent","records","headers","header","time","stats","record","start","parser","err","existingRows","newRows","row","existingRow","csvString","hash","totalTime","fileSize","mtime","fileName","fileNameIndex","hashs","size","baseName","data","stat","ComputeHashIndexCache","indexFilePath","indexLine"],"mappings":"sDAAA,OAAQ,WAAAA,MAAc,UAItB,IAAIC,EAAa,YAAY,QAC7BA,EAAaA,EAAW,QAAQ,MAAO,MAAM,EAC7CA,EAAaA,EAAa,aAC1B,IAAMC,EAAY,IAAI,IAAID,CAAU,EAAE,KACtC,QAAQ,IAAI,eAAgBC,CAAS,EAE9B,IAAMC,EAAN,KAAqB,CAChB,QAER,YAAYC,EAAoB,CAC5B,KAAK,QAAU,IAAIJ,EAAQ,CACvB,WAAY,EAEZ,SAAUI,GAAc,QAAQ,IAAI,YAAcF,CACtD,CAAC,CACL,CAQA,MAAa,YAAYG,EAAkBC,EAAsD,CAC7F,OAAO,KAAK,QAAQ,IAAI,CAAC,SAAAD,EAAU,WAAAC,CAAU,CAAC,CAClD,CACJ,EC3BO,IAAMC,EAAN,KAA8C,CAGjD,YAAoBC,EAAkCJ,EAAoB,CAAtD,gBAAAI,EAChB,KAAK,eAAiB,IAAIL,EAAeC,CAAU,CACvD,CAJQ,eAMR,MAAM,mBAAmBC,EAAkBI,EAAwC,CAE/E,IAAMC,EAAe,KAAK,WAAW,OAAOC,GAAY,CAACF,EAASE,CAAQ,CAAC,EAG3E,GAAID,EAAa,SAAW,EACxB,QAIS,MAAM,KAAK,eAAe,YAAYL,EAAUK,CAAY,GAGpE,QAAQ,CAACE,EAAKC,IAAU,CACzB,IAAMC,EAAWJ,EAAaG,CAAK,EACnCJ,EAASK,CAAQ,EAAIF,CACzB,CAAC,CACL,CACJ,EC5BA,OAAQ,oBAAAG,EAAkB,YAAYC,MAAS,KAC/C,OAAQ,SAAAC,MAAY,YACpB,OAAQ,SAASC,MAAgB,iBACjC,OAAQ,aAAAC,MAAgB,qBCDxB,OAAQ,UAAAC,EAAO,aAAAC,MAAgB,cAE/B,eAAsBC,EAAYjB,EAAoC,CAClE,GAAI,CACA,aAAMe,EAAOf,EAAUgB,EAAU,IAAI,EAC9B,EACX,MAAQ,CACJ,MAAO,EACX,CACJ,CDNA,OAAOE,MAAU,OACjB,OAAQ,iBAAAC,MAAoB,cAQrB,IAAMC,EAAgB,CAAC,OAAQ,OAAQ,OAAO,EAExCC,EAAN,KAAuB,CAU1B,YAAoBrB,EAAyBG,EAAkC,0BAAoD,EAAG,CAAlH,cAAAH,EAAyB,gBAAAG,EACzC,GAAI,CAACH,EACD,MAAM,IAAI,MAAM,yBAAyB,CAEjD,CAbQ,MAAgC,IAAI,IACpC,WACA,aAAuB,IACvB,kBAA4B,EAC5B,cACA,mBAA8B,GAC9B,WAAsB,GACtB,YAQD,UAAmC,CACtC,OAAO,IAAI,IAAI,KAAK,KAAK,CAC7B,CAMA,MAAM,KAAKsB,EAAW,GAAM,CACxB,OAAK,KAAK,cACN,KAAK,YAAc,IAAI,QAAc,MAAOC,EAASC,IAAW,CAC5D,GAAI,CACA,GAAI,CAAC,KAAK,gBAAgB,KAAK,QAAQ,EACnC,MAAM,IAAI,MAAM,4BAA4B,EAEhD,MAAM,KAAK,UAAU,EACjBF,GACA,KAAK,MAAM,EAEfC,EAAQ,CACZ,OAAQE,EAAG,CACPD,EAAOC,CAAC,CACZ,CACJ,CAAC,GAEE,KAAK,WAChB,CAGA,gBAAiBC,EAA6B,CAC1C,IAAMC,EAAUd,EAAUa,EAAY,CAClC,IAAK,GACL,QAAS,GACT,iBAAkB,EACtB,CAAC,EAED,GAAIC,EAAQ,SAAW,EAEnB,MAAO,GAIX,IAAMC,EAAU,OAAO,KAAKD,EAAQ,CAAC,CAAC,EAOtC,MAHwB,CAAC,OAAQ,OAAQ,QAAS,GAAG,KAAK,UAAU,EAG7C,MAAME,GAAUD,EAAQ,SAASC,CAAM,CAAC,CACnE,CAEO,OAAQ,CACX,KAAK,cAAc,KAAK,YAAY,CACxC,CAEO,cAAe,CACd,KAAK,YACLV,EAAc,KAAK,UAAU,CAErC,CAEQ,cAAcW,EAAc,CAChC,KAAK,aAAa,EAClB,KAAK,aAAeA,EACpB,KAAK,WAAa,YAAY,IAAM,KAAK,gBAAgB,EAAGA,CAAI,CACpE,CAEA,MAAa,WAAkC,CAC3C,GAAI,MAAMb,EAAY,KAAK,QAAQ,EAAG,CAElC,IAAMc,EAAQ,MAAMpB,EAAG,KAAK,KAAK,QAAQ,EACzC,GAAI,KAAK,oBAAsBoB,EAAM,KAAM,CAEvC,IAAMJ,EAAuB,MAAM,KAAK,QAAQ,EAChD,QAAWK,KAAUL,EACjB,KAAK,MAAM,IAAIK,EAAO,KAAMA,CAAM,EAEtC,YAAK,kBAAoBD,EAAM,KAC/B,KAAK,cAAgBJ,EACdA,CACX,KACI,QAAO,KAAK,aAEpB,CACA,MAAO,CAAC,CACZ,CAEQ,oBAAkC,CACtC,OAAO,MAAM,KAAK,KAAK,MAAM,OAAO,CAAC,CACzC,CAEA,MAAc,SAAgC,CAC1C,GAAI,CAAE,MAAMV,EAAY,KAAK,QAAQ,EACjC,MAAO,CAAC,EAEZ,IAAMgB,EAAQ,YAAY,IAAI,EAExBC,EAAStB,EAAM,CACjB,QAAS,GACT,iBAAkB,EACtB,CAAC,EAEKe,EAAuB,CAAC,EAE9B,OAAO,IAAI,QAAQ,CAACJ,EAASC,IAAW,CACpCd,EAAiB,KAAK,QAAQ,EACzB,KAAKwB,CAAM,EACX,GAAG,OAASF,GAAW,CACpBL,EAAQ,KAAKK,CAAM,CACvB,CAAC,EAAE,GAAG,MAAO,IAAM,CACnBT,EAAQI,CAAO,EACf,QAAQ,IAAI,mBAAmB,YAAY,IAAI,EAAIM,CAAK,IAAI,CAChE,CAAC,EAAE,GAAG,QAAUE,GAAQ,CACpBX,EAAOW,CAAG,CACd,CAAC,CACL,CAAC,CACL,CAEA,MAAc,iBAAiC,CAC3C,GAAI,KAAK,oBAAsB,CAAC,KAAK,WACjC,OAEJ,KAAK,WAAa,GAClB,KAAK,mBAAqB,GAC1B,IAAMF,EAAQ,YAAY,IAAI,EAC1BG,EAA4B,MAAM,KAAK,UAAU,EAErD,GAAI,KAAK,MAAM,OAAS,EAAG,CAGvB,IAAMC,EAFyB,KAAK,mBAAmB,EAE7B,OAAOC,GAAO,CAACF,EAAa,KAAKG,GAAeA,EAAY,OAASD,EAAI,IAAI,CAAC,EAExG,GAAID,EAAQ,SAAW,EAAG,CAEtB,IAAMG,EAAY1B,EAAUuB,EAAS,CACjC,OAAQD,EAAa,SAAW,EAChC,QAAS,CACL,CAAC,IAAK,OAAQ,OAAQ,MAAM,EAC5B,CAAC,IAAK,OAAQ,OAAQ,MAAM,EAC5B,CAAC,IAAK,QAAS,OAAQ,OAAO,EAC9B,GAAG,KAAK,WAAW,IAAIK,IAAS,CAAC,IAAKA,EAAM,OAAQA,CAAI,EAAE,CAC9D,CACJ,CAAC,EAGD,MAAM9B,EAAG,WAAW,KAAK,SAAU6B,CAAS,CAChD,CACJ,CACA,IAAME,EAAY,YAAY,IAAI,EAAIT,EACtC,QAAQ,IAAI,kBAAkBS,CAAS,IAAI,EAEvCA,EAAY,GAAK,KAAK,eACtB,KAAK,cAAcA,EAAY,EAAE,EACjC,QAAQ,IAAI,oCAAoCA,EAAY,EAAE,IAAI,GAEtE,KAAK,mBAAqB,EAC9B,CAEO,cAAc1C,EAAkB2C,EAAkBC,EAA0B,CAC/E,IAAMC,EAAW3B,EAAK,SAASlB,CAAQ,EACnC8C,EAAgB,KAAK,MAAM,IAAID,CAAQ,EAC3C,GAAGC,GACC,GAAGA,EAAc,OAEb,GAAIA,EAAc,OAAUH,EAAW,IAAOG,EAAc,QAAUF,EAClE,OAAOE,UAIPA,EAAc,OAAUH,EAAW,GACnC,OAAOG,EAWnB,OAAO,IACX,CAEO,WAAW9C,EAAkB2C,EAAkBC,EAAeG,EAA2D,CAC5H,GAAI,CAAC/C,GAAY,CAAC2C,GAAY,CAACC,GAAS,CAACG,EACrC,MAAM,IAAI,MAAM,oBAAoB,EAExC,IAAMC,EAAOL,EAAW,GAClBM,EAAW/B,EAAK,SAASlB,CAAQ,EACjCkD,EAAO,CAAC,KAAMD,EAAU,KAAMD,EAAM,MAAOJ,EAAO,GAAGG,CAAK,EAChE,KAAK,MAAM,IAAIE,EAAUC,CAAI,EAC7B,KAAK,WAAa,EACtB,CAEJ,EEjOA,OAAQ,QAAAC,MAAW,cACnB,OAAOjC,MAAU,OAEV,IAAMkC,EAAN,KAAwD,CAI3D,YAAYC,EAA8BlD,EAAoC,0BAAqD,EAAEJ,EAAoB,CAA/G,gBAAAI,EACtC,KAAK,aAAe,IAAID,EAAa,KAAK,WAAWH,CAAU,EAC/D,KAAK,iBAAmB,IAAIsB,EAAiBgC,CAAa,CAC9D,CANA,iBACA,aAOA,MAAM,mBAAmBrD,EAAkBI,EAAwC,CAC/E,MAAM,KAAK,iBAAiB,KAAK,EACjC,IAAI2B,EAAQ,MAAMoB,EAAKnD,CAAQ,EAC/B,GAAI,KAAK,iBAAiB,SAAS,EAAE,IAAIkB,EAAK,SAASlB,CAAQ,CAAC,EAAG,CAC/D,IAAMsD,EAAY,KAAK,iBAAiB,cAActD,EAAU+B,EAAM,KAAMA,EAAM,MAAM,YAAY,CAAC,EACrG,GAAGuB,EACC,QAAWb,KAAQ,KAAK,WAChB,CAACrC,EAASqC,CAAI,GAAKa,EAAUb,CAAI,IACjCrC,EAASqC,CAAI,EAAIa,EAAUb,CAAI,EAI/C,CACA,MAAM,KAAK,aAAa,mBAAmBzC,EAAUI,CAAQ,EAC7D,KAAK,iBAAiB,WAAWJ,EAAU+B,EAAM,KAAMA,EAAM,MAAM,YAAY,EAAG3B,CAAQ,CAC9F,CACJ","sourcesContent":["import {Piscina} from \"piscina\";\nimport {CID_ALGORITHM_NAMES} from \"../MultiHashData\";\n\n// Construct the URL for the current module\nlet distFolder = import.meta.dirname;\ndistFolder = distFolder.replace('src', 'dist');\ndistFolder = distFolder + \"/worker.js\";\nconst workerUrl = new URL(distFolder).href;\nconsole.log(\"Worker URL: \", workerUrl);\n\nexport class FileIDComputer {\n    private piscina: Piscina;\n\n    constructor(workerPath?:string) {\n        this.piscina = new Piscina({\n            maxThreads: 4,\n            //filename: new URL('./ShaComputeWorker.ts', import.meta.url).href\n            filename: workerPath || process.env.WORKER_URL || workerUrl\n        });\n    }\n\n    /**\n     * Compute the CIDs of a file using specific algorithms\n     * @param filePath The path to the file\n     * @param algorithms Array of algorithms ('sha256', 'sha1')\n     * @returns Array of CIDs (in the order of the algorithms)\n     */\n    public async computeCIDs(filePath: string, algorithms: CID_ALGORITHM_NAMES[]): Promise<string[]> {\n        return this.piscina.run({filePath, algorithms});\n    }\n}\n","import { FileIDComputer } from \"./fileID/FileIDComputer\";\nimport {CID_ALGORITHM_NAMES, ComputeInterface, MultiHashData} from \"./MultiHashData\";\n\nexport class HashComputer implements ComputeInterface{\n    private fileIDComputer:FileIDComputer;\n\n    constructor(private targetHash: CID_ALGORITHM_NAMES[],workerPath?:string) {\n        this.fileIDComputer = new FileIDComputer(workerPath);\n    }\n\n    async computeMissingHash(filePath: string, metadata: MultiHashData): Promise<void> {\n        // Dynamically determine which hashes are needed\n        const neededHashes = this.targetHash.filter(hashName => !metadata[hashName]);\n\n        // If all hashes are already computed, skip the processing\n        if (neededHashes.length === 0) {\n            return;\n        }\n\n        // Compute only the needed CIDs\n        const cids = await this.fileIDComputer.computeCIDs(filePath, neededHashes);\n\n        // Map the computed CIDs back to their respective metadata properties\n        cids.forEach((cid, index) => {\n            const hashType = neededHashes[index];\n            metadata[hashType] = cid;\n        });\n    }\n}\n","import {createReadStream, promises as fs} from 'fs';\nimport {parse} from 'csv-parse';\nimport {parse as parseSync} from 'csv-parse/sync';\nimport {stringify} from 'csv-stringify/sync';\nimport {existsAsync} from \"./ExistsAsync\";\nimport path from \"path\";\nimport {clearInterval} from \"node:timers\";\nimport {CID_ALGORITHM_NAMES} from \"./MultiHashData\";\n\ninterface IndexLine extends Partial<Record<CID_ALGORITHM_NAMES, string>> {\n    path: string;\n    size: string;\n    mtime: string;\n}\nexport const INDEX_HEADERS = ['path', 'size', 'mtime'];\n\nexport class HashIndexManager {\n    private cache: Map<string, IndexLine> = new Map<string, IndexLine>();\n    private intervalId: NodeJS.Timeout;\n    private intervalTime: number = 30000;\n    private lastIndexFileSize: number = 0; //size of the index file last time it was read\n    private lastCacheFile: IndexLine[]; //state of the file last time it was read\n    private indexOpsInProgress: boolean = false;\n    private hasChanged: boolean = false;\n    private initialLoad;\n\n    constructor(private filePath: string,private targetHash:CID_ALGORITHM_NAMES[]= [CID_ALGORITHM_NAMES.sha1,CID_ALGORITHM_NAMES.sha256]) {\n        if (!filePath) {\n            throw new Error('Invalid index file path');\n        }\n    }\n\n    public getCache(): Map<string, IndexLine> {\n        return new Map(this.cache);\n    }\n\n    /**\n     * After init consseutively calls to this method will not reload the index\n     * @param autosave\n     */\n    async init(autosave = true) {\n        if (!this.initialLoad) {\n            this.initialLoad = new Promise<void>(async (resolve, reject) => {\n                try {\n                    if (!this.checkCSVHeaders(this.filePath)) {\n                        throw new Error('Invalid index file headers');\n                    }\n                    await this.loadIndex();\n                    if (autosave) {\n                        this.start();\n                    }\n                    resolve();\n                }catch (e) {\n                    reject(e);\n                }\n            });\n        }\n        return this.initialLoad;\n    }\n\n    // Function to check CSV headers\n    checkCSVHeaders (csvContent: string): boolean {\n        const records = parseSync(csvContent, {\n            bom: true,\n            columns: true,\n            skip_empty_lines: true,\n        });\n\n        if (records.length === 0) {\n            //we will write the headers\n            return true;\n        }\n\n        // Extract headers\n        const headers = Object.keys(records[0]);\n\n        // Define required headers\n        //from the IndexLine interface\n        const requiredHeaders = ['path', 'size', 'mtime', ...this.targetHash];\n\n        // Check if all required headers are present\n        return requiredHeaders.every(header => headers.includes(header));\n    };\n\n    public start() {\n        this.startAutoSave(this.intervalTime);\n    }\n\n    public stopAutoSave() {\n        if (this.intervalId) {\n            clearInterval(this.intervalId);\n        }\n    }\n\n    private startAutoSave(time: number) {\n        this.stopAutoSave();\n        this.intervalTime = time;\n        this.intervalId = setInterval(() => this.saveCacheToFile(), time);\n    }\n\n    public async loadIndex(): Promise<IndexLine[]> {\n        if (await existsAsync(this.filePath)) {\n            // check the file size and if it did not change, do not read the file\n            const stats = await fs.stat(this.filePath);\n            if (this.lastIndexFileSize !== stats.size) {\n                // Read existing file content and parse it\n                const records: IndexLine[] = await this.readCsv();\n                for (const record of records) {\n                    this.cache.set(record.path, record);\n                }\n                this.lastIndexFileSize = stats.size;\n                this.lastCacheFile = records;\n                return records;\n            } else {\n                return this.lastCacheFile;\n            }\n        }\n        return [];\n    }\n\n    private loadIndexFromCache(): IndexLine[] {\n        return Array.from(this.cache.values());\n    }\n\n    private async readCsv(): Promise<IndexLine[]> {\n        if (!(await existsAsync(this.filePath))) {\n            return [];\n        }\n        const start = performance.now();\n\n        const parser = parse({\n            columns: true,\n            skip_empty_lines: true,\n        });\n\n        const records: IndexLine[] = [];\n\n        return new Promise((resolve, reject) => {\n            createReadStream(this.filePath)\n                .pipe(parser)\n                .on('data', (record) => {\n                    records.push(record);\n                }).on('end', () => {\n                resolve(records);\n                console.log(`Index read time ${performance.now() - start}ms`);\n            }).on('error', (err) => {\n                reject(err);\n            });\n        });\n    }\n\n    private async saveCacheToFile(): Promise<void> {\n        if (this.indexOpsInProgress || !this.hasChanged) {\n            return;\n        }\n        this.hasChanged = false;\n        this.indexOpsInProgress = true;\n        const start = performance.now();\n        let existingRows: IndexLine[] = await this.loadIndex();\n\n        if (this.cache.size !== 0) {\n            const cacheRows: IndexLine[] = this.loadIndexFromCache();\n            // Filter out cacheRows that are already in the file\n            const newRows = cacheRows.filter(row => !existingRows.find(existingRow => existingRow.path === row.path));\n\n            if (newRows.length !== 0) {\n                // Serialize new cacheRows to CSV string\n                const csvString = stringify(newRows, {\n                    header: existingRows.length === 0, // Only add header if the file was empty\n                    columns: [\n                        {key: 'path', header: 'path'},\n                        {key: 'size', header: 'size'},\n                        {key: 'mtime', header: 'mtime'},\n                        ...this.targetHash.map(hash => ({key: hash, header: hash})),\n                    ],\n                });\n\n                // Append new cacheRows to the file\n                await fs.appendFile(this.filePath, csvString);\n            }\n        }\n        const totalTime = performance.now() - start;\n        console.log(`Index saved in ${totalTime}ms`);\n        // Check if the time to save the index is greater than the interval time. increase the interval time if needed\n        if (totalTime * 10 > this.intervalTime) {\n            this.startAutoSave(totalTime * 10);\n            console.log(`Index save interval increased to ${totalTime * 10}ms`);\n        }\n        this.indexOpsInProgress = false;\n    }\n\n    public getCidForFile(filePath: string, fileSize: number, mtime: string): IndexLine {\n        const fileName = path.basename(filePath);\n        let fileNameIndex = this.cache.get(fileName);\n        if(fileNameIndex) {\n            if(fileNameIndex.mtime) {\n                //if we have a mtime, we need to check it\n                if (fileNameIndex.size === (fileSize + \"\") && fileNameIndex.mtime === mtime) {\n                    return fileNameIndex;\n                }\n            }else {\n                //mtime is optional\n                if (fileNameIndex.size === (fileSize + \"\")) {\n                    return fileNameIndex;\n                }\n            }\n        }\n\n        // 3 - if not found, delete the entry (keeps the index clean)\n        /*if (fileNameIndex && fileNameIndex.size !== (fileSize + \"\") && pathIndex && pathIndex.size !== (fileSize + \"\")) {\n            this.cache.delete(fileName);\n            this.cache.delete(filePath);\n        }*/\n\n        return null;\n    }\n\n    public addFileCid(filePath: string, fileSize: number, mtime: string, hashs: Partial<Record<CID_ALGORITHM_NAMES, string>>): void {\n        if (!filePath || !fileSize || !mtime || !hashs) {\n            throw new Error('Invalid parameters');\n        }\n        const size = fileSize + \"\";\n        const baseName = path.basename(filePath);\n        const data = {path: baseName, size: size, mtime: mtime, ...hashs};\n        this.cache.set(baseName, data);\n        this.hasChanged = true;\n    }\n\n}","// Example of checking if a file exists asynchronously\n// Note: `existsSync` does not have a direct async equivalent, so we use `access` instead.\nimport {access,constants} from \"fs/promises\";\n\nexport async function existsAsync(filePath: string): Promise<boolean> {\n    try {\n        await access(filePath, constants.F_OK);\n        return true; // File exists\n    } catch {\n        return false; // File does not exist\n    }\n}","import {HashComputer} from \"./HashComputer\";\nimport {CID_ALGORITHM_NAMES, ComputeInterface, MultiHashData} from \"./MultiHashData\";\nimport {HashIndexManager} from \"./HashIndexManager\";\nimport {stat} from \"fs/promises\";\nimport path from \"path\";\n\nexport class ComputeHashIndexCache implements ComputeInterface {\n    hashIndexManager: HashIndexManager;\n    hashComputer: HashComputer;\n\n    constructor(indexFilePath: string,private targetHash: CID_ALGORITHM_NAMES[] = [CID_ALGORITHM_NAMES.sha1, CID_ALGORITHM_NAMES.sha256],workerPath?:string) {\n        this.hashComputer = new HashComputer(this.targetHash,workerPath);\n        this.hashIndexManager = new HashIndexManager(indexFilePath);\n    }\n\n    async computeMissingHash(filePath: string, metadata: MultiHashData): Promise<void> {\n        await this.hashIndexManager.init();\n        let stats = await stat(filePath);\n        if (this.hashIndexManager.getCache().has(path.basename(filePath))) {\n            const indexLine = this.hashIndexManager.getCidForFile(filePath, stats.size, stats.mtime.toISOString());\n            if(indexLine) {\n                for (const hash of this.targetHash) {\n                    if (!metadata[hash] && indexLine[hash]) {\n                        metadata[hash] = indexLine[hash];\n                    }\n                }\n            }\n        }\n        await this.hashComputer.computeMissingHash(filePath, metadata);\n        this.hashIndexManager.addFileCid(filePath, stats.size, stats.mtime.toISOString(), metadata);\n    }\n}"]}